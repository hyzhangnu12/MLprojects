{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "003_TopicModel_PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BIszqyp8lzSU",
        "IdZPmaFPtwyq",
        "9hHCLbrpfSqO",
        "Pa4UrSFFvizm",
        "_Oxvz01vfaq6",
        "-OTK4DVHxcR0",
        "ezlCICGwzvQu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfAJhrgFo5Tv"
      },
      "source": [
        "# **Topic Modeling with PySpark and Spark NLP**\n",
        "Topic Modelling is a statistical approach for data modelling that helps in discovering underlying topics that are present in the collection of documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ9ZF9pQqW2X"
      },
      "source": [
        "In this project we built the NLP pipeline with Spark NLP and trained a topic model with PySpark. (see [here](https://github.com/maobedkova/TopicModelling_PySpark_SparkNLP/blob/master/Topic_Modelling_with_PySpark_and_Spark_NLP.ipynb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIszqyp8lzSU"
      },
      "source": [
        "# **Part 0: PySpark Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPmFVedSA68v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "7d7576b0-42c5-4f5b-c339-600a014e3431"
      },
      "source": [
        "## update apt-get\n",
        "!apt-get update\n",
        "\n",
        "## Install java\n",
        "import os\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "!java -version\n",
        "\n",
        "## Install pyspark\n",
        "!pip install pyspark==2.4.5\n",
        "\n",
        "## Install Spark NLP\n",
        "!pip install spark-nlp==2.4.5\n",
        "\n",
        "## Install nltk\n",
        "#!pip install nltk\n",
        "\n",
        "## start the Spark session through Spark NLP\n",
        "import sparknlp\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n",
            "Requirement already satisfied: pyspark==2.4.5 in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark==2.4.5) (0.10.7)\n",
            "Requirement already satisfied: spark-nlp==2.4.5 in /usr/local/lib/python3.6/dist-packages (2.4.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E9V97lh_LBj"
      },
      "source": [
        "# **Part 1: Data Loading**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfgD9jhRrFEF"
      },
      "source": [
        "In this project, I analyzed three datasets which from Kaggle:\n",
        "- [Amazon Musical Instruments Review](https://www.kaggle.com/eswarchandt/amazon-music-reviews)\n",
        "- [A Million News Headlines](https://www.kaggle.com/therohk/million-headlines)\n",
        "- [Amazon Watch Review]\n",
        "- [Youtube PetChannel Review]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qRFqVCfo_HY"
      },
      "source": [
        "## 1.1 Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sga628Xqypd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bd49a1d-e499-4e7d-c092-6737e931639c"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('ggdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at ggdrive; to attempt to forcibly remount, call drive.mount(\"ggdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdZPmaFPtwyq"
      },
      "source": [
        "## 1.2 Read data from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19uyI_8dAd3j"
      },
      "source": [
        "datasets = {'amazonMusic': ['ggdrive/My Drive/dataSet/NLP/Musical_Instruments_5.json',\n",
        "                            'reviewText', 6],\n",
        "            'abcnews': ['ggdrive/My Drive/Skills/data/abcnews-date-text.csv',\n",
        "                        'headline_text', 20],\n",
        "            'amazonWatch': ['ggdrive/My Drive/Skills/data/watch_reviews.tsv',\n",
        "                            'review_body', 6]}\n",
        "\n",
        "data_nm = ['amazonMusic', 'abcnews', 'amazonWatch'][0]\n",
        "data_params = datasets[data_nm]\n",
        "\n",
        "if data_nm == 'amazonMusic':\n",
        "  data = spark.read.json(data_params[0])\n",
        "elif data_nm == 'abcnews':\n",
        "  data = spark.read.option('header', 'true')\\\n",
        "         .option('mode', 'DROPMALFORMED')\\\n",
        "         .option('inferSchema', True)\\\n",
        "         .csv(data_params[0])\n",
        "elif data_nm == 'amazonWatch':\n",
        "  data = spark.read.csv(data_params[0], sep=r'\\t', header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BohpGAxPuezM"
      },
      "source": [
        "## 1.3 Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_4_zyfNBlzB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7f3e6d00-8237-4169-b730-6d56bcf2eef2"
      },
      "source": [
        "# spark dataframe schema\n",
        "data.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- asin: string (nullable = true)\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- overall: double (nullable = true)\n",
            " |-- reviewText: string (nullable = true)\n",
            " |-- reviewTime: string (nullable = true)\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- reviewerName: string (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- unixReviewTime: long (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBgMDyVQDU9B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7f3fa4b3-156c-4554-dcfe-77534b5d8a70"
      },
      "source": [
        "# how the data looks like\n",
        "data.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
            "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "|1384719342|  [0, 0]|    5.0|Not much to write...|02 28, 2014|A2IBPI20UZIR0U|cassandra tu \"Yea...|                good|    1393545600|\n",
            "|1384719342|[13, 14]|    5.0|The product does ...|03 16, 2013|A14VAT5EAX3D9S|                Jake|                Jake|    1363392000|\n",
            "|1384719342|  [1, 1]|    5.0|The primary job o...|08 28, 2013|A195EZSQDW3E21|Rick Bennette \"Ri...|It Does The Job Well|    1377648000|\n",
            "|1384719342|  [0, 0]|    5.0|Nice windscreen p...|02 14, 2014|A2C00NNG1ZQQG2|RustyBill \"Sunday...|GOOD WINDSCREEN F...|    1392336000|\n",
            "|1384719342|  [0, 0]|    5.0|This pop filter i...|02 21, 2014| A94QU4C90B1AX|       SEAN MASLANKA|No more pops when...|    1392940800|\n",
            "|B00004Y2UT|  [0, 0]|    5.0|So good that I bo...|12 21, 2012|A2A039TZMZHH9Y| Bill Lewey \"blewey\"|      The Best Cable|    1356048000|\n",
            "|B00004Y2UT|  [0, 0]|    5.0|I have used monst...|01 19, 2014|A1UPZM995ZAH90|               Brian|Monster Standard ...|    1390089600|\n",
            "|B00004Y2UT|  [0, 0]|    3.0|I now use this ca...|11 16, 2012| AJNFQI3YR6XJ5|   Fender Guy \"Rick\"|Didn't fit my 199...|    1353024000|\n",
            "|B00004Y2UT|  [0, 0]|    5.0|Perfect for my Ep...| 07 6, 2008|A3M1PLEYNDEYO8|     G. Thomas \"Tom\"|         Great cable|    1215302400|\n",
            "|B00004Y2UT|  [0, 0]|    5.0|Monster makes the...| 01 8, 2014| AMNTZU1YQN1TH|         Kurt Robair|Best Instrument C...|    1389139200|\n",
            "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1YbHHIKEnrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "7c3d797d-22f1-404e-a3dd-6049d1ea4e1b"
      },
      "source": [
        "# the number of rows\n",
        "print(f'Totally, we have {data.count()} rows of data.')\n",
        "\n",
        "# target column\n",
        "text_col = data_params[1]\n",
        "print(f'For column \"{text_col}\", we have {data.select(text_col).distinct().count()} rows of distinct values')\n",
        "review_text = data.select(text_col).na.drop()#.dropDuplicates()\n",
        "\n",
        "#review_text = spark.createDataFrame(review_text.collect()[:1000])\n",
        "#review_text = review_text.sample(withReplacement=False, fraction=0.01, seed=2020)\n",
        "\n",
        "print(f'After clean-up and sampling, we have {review_text.count()} rows of {text_col} data:')\n",
        "review_text.show(10, truncate=90)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Totally, we have 10261 rows of data.\n",
            "For column \"reviewText\", we have 10255 rows of distinct values\n",
            "After clean-up and sampling, we have 10261 rows of reviewText data:\n",
            "+------------------------------------------------------------------------------------------+\n",
            "|                                                                                reviewText|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "|Not much to write about here, but it does exactly what it's supposed to. filters out th...|\n",
            "|The product does exactly as it should and is quite affordable.I did not realized it was...|\n",
            "|The primary job of this device is to block the breath that would otherwise produce a po...|\n",
            "|Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck...|\n",
            "|This pop filter is great. It looks and performs like a studio filter. If you're recordi...|\n",
            "|So good that I bought another one.  Love the heavy cord and gold connectors.  Bass soun...|\n",
            "|I have used monster cables for years, and with good reason. The lifetime warranty is wo...|\n",
            "|I now use this cable to run from the output of my pedal chain to the input of my Fender...|\n",
            "|Perfect for my Epiphone Sheraton II.  Monster cables are well constructed.  I have seve...|\n",
            "|Monster makes the best cables and a lifetime warranty doesnt hurt either. This isnt the...|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkMWsrcoQyH2"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "#review_text.select(F.count(F.when(F.col(text_col).isNull() | F.isnan(text_col), text_col)).alias(text_col)).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hHCLbrpfSqO"
      },
      "source": [
        "# **Part 2: Spark NLP pipeline** ([annotators](https://nlp.johnsnowlabs.com/docs/en/annotators))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PjxUquwv83c"
      },
      "source": [
        "## 2.1 DocumentAssembler (see [here](https://nlp.johnsnowlabs.com/docs/en/transformers#documentassembler-getting-data-in))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwOdzQ_PAJi0"
      },
      "source": [
        "from sparknlp.base import DocumentAssembler\n",
        "\n",
        "documentAssembler = DocumentAssembler() \\\n",
        "     .setInputCol(text_col) \\\n",
        "     .setOutputCol('document')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facUm7iMwUKZ"
      },
      "source": [
        "## 2.2 Tokenizer (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGOLmEzJDCYW"
      },
      "source": [
        "from sparknlp.annotator import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "     .setInputCols(['document']) \\\n",
        "     .setOutputCol('tokenized')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA98q-HCxVjb"
      },
      "source": [
        "## 2.3 Normalizer (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#normalizer))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTuQv1VXD8xu"
      },
      "source": [
        "from sparknlp.annotator import Normalizer\n",
        "\n",
        "normalizer = Normalizer() \\\n",
        "     .setInputCols(['tokenized']) \\\n",
        "     .setOutputCol('normalized') \\\n",
        "     .setLowercase(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80FaYj0axg1r"
      },
      "source": [
        "## 2.4 LemmatizerModel (see [here](https://nlp.johnsnowlabs.com/docs/en/models#english---models))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1lvJInOEEAy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5d9beb9b-2a1f-4d66-df89-377e894bfc71"
      },
      "source": [
        "from sparknlp.annotator import LemmatizerModel\n",
        "\n",
        "lemmatizer = LemmatizerModel.pretrained() \\\n",
        "     .setInputCols(['normalized']) \\\n",
        "     .setOutputCol('lemmatized')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKDZh-kkybKt"
      },
      "source": [
        "## 2.5 StopWordsCleaner (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#stopwordscleaner))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um9iOifSft2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "43d4a594-1fa1-44bb-a9b3-163d83d67251"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "eng_stopwords = stopwords.words('english')\n",
        "\n",
        "######\n",
        "from sparknlp.annotator import StopWordsCleaner\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner() \\\n",
        "     .setInputCols(['lemmatized']) \\\n",
        "     .setOutputCol('unigrams') \\\n",
        "     .setStopWords(eng_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW87_1g2yr3-"
      },
      "source": [
        "## 2.6 NGramGenerator (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#ngramgenerator))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsftJKunZO84"
      },
      "source": [
        "from sparknlp.annotator import NGramGenerator\n",
        "\n",
        "ngrammer = NGramGenerator() \\\n",
        "    .setInputCols(['lemmatized']) \\\n",
        "    .setOutputCol('ngrams') \\\n",
        "    .setN(3) \\\n",
        "    .setEnableCumulative(True) \\\n",
        "    .setDelimiter('_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymL8JUPrzV0R"
      },
      "source": [
        "## 2.7 PerceptronModel (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#postagger)) for POS (Part Of Speech)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilOwKkC20Xe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f3c4206a-048a-48ae-b14f-135ee5c57061"
      },
      "source": [
        "from sparknlp.annotator import PerceptronModel\n",
        "\n",
        "pos_tagger = PerceptronModel.pretrained('pos_anc') \\\n",
        "    .setInputCols(['document', 'lemmatized']) \\\n",
        "    .setOutputCol('pos')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 4.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl6Xs_zE0Fc8"
      },
      "source": [
        "## 2.8 Finisher (see [here](https://nlp.johnsnowlabs.com/docs/en/transformers#finisher))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3eYHx-KrDxU"
      },
      "source": [
        "from sparknlp.base import Finisher\n",
        "\n",
        "finisher = Finisher() \\\n",
        "     .setInputCols(['unigrams', 'ngrams', 'pos']) \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP-kJKHQ0T8e"
      },
      "source": [
        "## 2.9 Basic NLP Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo4ixwfsrMPh"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline() \\\n",
        "     .setStages([documentAssembler,                  \n",
        "                 tokenizer,\n",
        "                 normalizer,                  \n",
        "                 lemmatizer,                  \n",
        "                 stopwords_cleaner, \n",
        "                 ngrammer,\n",
        "                 pos_tagger,  \n",
        "                 finisher])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yXiHvEE0gYx"
      },
      "source": [
        "## 2.10 Fit and transform review_text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCkceTwhrOf0"
      },
      "source": [
        "processed_review = pipeline.fit(review_text).transform(review_text)\n",
        "#processed_review.select(*(F.count(F.when(F.size(F.col(c)) == 0, c)).alias(c)\\\n",
        "#                          for c in processed_review.columns[1:])).show()\n",
        "\n",
        "processed_review = processed_review.filter(F.size(F.col('finished_unigrams')) > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7ovKGdr0p6J"
      },
      "source": [
        "## 2.11 processed_review looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-vuMJZD9Lwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "07cdf80e-c5cd-4869-9eea-a651436b3d44"
      },
      "source": [
        "processed_review.show(10, truncate=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|                    reviewText|             finished_unigrams|               finished_ngrams|                  finished_pos|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|Not much to write about her...|[much, write, exactly, supp...|[not, much, to, write, abou...|[RB, JJ, TO, VB, IN, RB, CC...|\n",
            "|The product does exactly as...|[product, exactly, quite, a...|[the, product, do, exactly,...|[DT, NN, VBP, RB, IN, PRP, ...|\n",
            "|The primary job of this dev...|[primary, job, device, bloc...|[the, primary, job, of, thi...|[DT, JJ, NN, IN, DT, NN, VB...|\n",
            "|Nice windscreen protects my...|[nice, windscreen, protect,...|[nice, windscreen, protect,...|[JJ, NN, NN, NNP, NN, JJ, C...|\n",
            "|This pop filter is great. I...|[pop, filter, great, look, ...|[this, pop, filter, be, gre...|[DT, NN, NN, VB, JJ, PRP, V...|\n",
            "|So good that I bought anoth...|[good, buy, another, one, l...|[so, good, that, i, buy, an...|[RB, JJ, IN, NNP, VB, DT, C...|\n",
            "|I have used monster cables ...|[use, monster, cable, year,...|[i, have, use, monster, cab...|[NNP, VBP, NN, NN, NN, IN, ...|\n",
            "|I now use this cable to run...|[use, cable, run, output, p...|[i, now, use, this, cable, ...|[NNP, RB, VBP, DT, NN, TO, ...|\n",
            "|Perfect for my Epiphone She...|[perfect, epiphone, sherato...|[perfect, for, i, epiphone,...|[JJ, IN, NNP, NN, NN, NN, N...|\n",
            "|Monster makes the best cabl...|[monster, make, good, cable...|[monster, make, the, good, ...|[NN, NN, DT, JJ, NN, CC, DT...|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FnnKmIf2Ssc"
      },
      "source": [
        "## 2.12 POS tags of ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUEAaOogCve2"
      },
      "source": [
        "### 2.12.1 Join pos of unigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbPpOs8ndGE9"
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import types as T\n",
        "\n",
        "udf_join_arr = F.udf(lambda x: ' '.join(x), T.StringType())\n",
        "processed_review  = processed_review.withColumn('finished_pos', udf_join_arr(F.col('finished_pos')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G50ES8tcC8FQ"
      },
      "source": [
        "### 2.12.2 Transform joined pos into annotation format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKEpmfoba6M"
      },
      "source": [
        "pos_documentAssembler = DocumentAssembler() \\\n",
        "     .setInputCol('finished_pos') \\\n",
        "     .setOutputCol('pos_document')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smZ6-1dz2uf3"
      },
      "source": [
        "### 2.12.3 pos_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyZdZ7S8aGZ9"
      },
      "source": [
        "pos_tokenizer = Tokenizer() \\\n",
        "     .setInputCols(['pos_document']) \\\n",
        "     .setOutputCol('pos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8kJmdm52w-M"
      },
      "source": [
        "### 2.12.4 NGramGenerator of pos tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QnL0zwrW_w-"
      },
      "source": [
        "pos_ngrammer = NGramGenerator() \\\n",
        "    .setInputCols(['pos']) \\\n",
        "    .setOutputCol('pos_ngrams') \\\n",
        "    .setN(3) \\\n",
        "    .setEnableCumulative(True) \\\n",
        "    .setDelimiter('_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG3UTh0N23Yf"
      },
      "source": [
        "### 2.12.5 pos_finisher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiUGFlMHZqIZ"
      },
      "source": [
        "pos_finisher = Finisher() \\\n",
        "     .setInputCols(['pos', 'pos_ngrams']) \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSQ1XeNZ2--r"
      },
      "source": [
        "### 2.12.6 NLP pipeline for pos tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-AufeTzbYwM"
      },
      "source": [
        "pos_pipeline = Pipeline() \\\n",
        "     .setStages([pos_documentAssembler,                  \n",
        "                 pos_tokenizer,\n",
        "                 pos_ngrammer,  \n",
        "                 pos_finisher])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxQJcpiA3EBg"
      },
      "source": [
        "### 2.12.7 Pipeline fit and transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kfpx2azbmJI"
      },
      "source": [
        "processed_review = pos_pipeline.fit(processed_review).transform(processed_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUbDHzkZ3JzH"
      },
      "source": [
        "### 2.12.8 New processed review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0dBA85zf3Sd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2c257a64-83eb-448c-cb1f-fcc15a1a4ae4"
      },
      "source": [
        "processed_review.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|          reviewText|   finished_unigrams|     finished_ngrams|        finished_pos| finished_pos_ngrams|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Not much to write...|[much, write, exa...|[not, much, to, w...|[RB, JJ, TO, VB, ...|[RB, JJ, TO, VB, ...|\n",
            "|The product does ...|[product, exactly...|[the, product, do...|[DT, NN, VBP, RB,...|[DT, NN, VBP, RB,...|\n",
            "|The primary job o...|[primary, job, de...|[the, primary, jo...|[DT, JJ, NN, IN, ...|[DT, JJ, NN, IN, ...|\n",
            "|Nice windscreen p...|[nice, windscreen...|[nice, windscreen...|[JJ, NN, NN, NNP,...|[JJ, NN, NN, NNP,...|\n",
            "|This pop filter i...|[pop, filter, gre...|[this, pop, filte...|[DT, NN, NN, VB, ...|[DT, NN, NN, VB, ...|\n",
            "|So good that I bo...|[good, buy, anoth...|[so, good, that, ...|[RB, JJ, IN, NNP,...|[RB, JJ, IN, NNP,...|\n",
            "|I have used monst...|[use, monster, ca...|[i, have, use, mo...|[NNP, VBP, NN, NN...|[NNP, VBP, NN, NN...|\n",
            "|I now use this ca...|[use, cable, run,...|[i, now, use, thi...|[NNP, RB, VBP, DT...|[NNP, RB, VBP, DT...|\n",
            "|Perfect for my Ep...|[perfect, epiphon...|[perfect, for, i,...|[JJ, IN, NNP, NN,...|[JJ, IN, NNP, NN,...|\n",
            "|Monster makes the...|[monster, make, g...|[monster, make, t...|[NN, NN, DT, JJ, ...|[NN, NN, DT, JJ, ...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCXs_3yNfXbG"
      },
      "source": [
        "## 2.13 Filter messing pos tag combination for unigram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix2DZ3ALHkob"
      },
      "source": [
        "### 2.13.1 udf function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhhKK97NfEbd"
      },
      "source": [
        "def filter_pos(words, pos_tags):\n",
        "    return [word for word, pos in zip(words, pos_tags) ## not 1 : 1\n",
        "            if pos in ['JJ', 'NN', 'NNS', 'VB', 'VBP']]\n",
        "\n",
        "udf_filter_pos = F.udf(filter_pos, T.ArrayType(T.StringType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YveLNdrmm_nX"
      },
      "source": [
        "# Function to get rows at `rownums`\n",
        "def getrows(df, rownums=None):\n",
        "    return df.rdd.zipWithIndex()\\\n",
        "         .filter(lambda x: x[1] in rownums)\\\n",
        "         .map(lambda x: x[0])\n",
        "\n",
        "# Get rows at positions 0 and 2.\n",
        "#row02 = getrows(processed_review, rownums=[2]).collect()\n",
        "#for i in [1, 2, 3, 4]:\n",
        "#  print(len(row02[0][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_hy63My3rrV"
      },
      "source": [
        "### 2.13.2 Filter unigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEx5CHyqfWeG"
      },
      "source": [
        "#processed_review = processed_review.withColumn('filtered_unigrams',\n",
        "#      udf_filter_pos(F.col('finished_unigrams'), F.col('finished_pos')))\n",
        "#processed_review.select('filtered_unigrams').show(10, truncate=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEDG4jfD4Rux"
      },
      "source": [
        "## 2.14 Filter out improper POS combinations of n-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0cOckO_I79f"
      },
      "source": [
        "### 2.14.1 udf function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJd-nLnxgd1g"
      },
      "source": [
        "def filter_pos_combs(words, pos_tags):\n",
        "    return [word for word, pos in zip(words, pos_tags) \n",
        "            if (len(pos.split('_')) == 2 and \\\n",
        "                pos.split('_')[0] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                 pos.split('_')[1] in ['JJ', 'NN', 'NNS']) \\\n",
        "            or (len(pos.split('_')) == 3 and \\\n",
        "                pos.split('_')[0] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                 pos.split('_')[1] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                  pos.split('_')[2] in ['NN', 'NNS'])]\n",
        "    \n",
        "udf_filter_pos_combs = F.udf(filter_pos_combs, T.ArrayType(T.StringType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zjj8b9v425f"
      },
      "source": [
        "### 2.14.2 Transform "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH1gNrz6giPU"
      },
      "source": [
        "processed_review = processed_review.withColumn('filtered_ngrams',\n",
        "    udf_filter_pos_combs(F.col('finished_ngrams'), F.col('finished_pos_ngrams')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kA7epRY5HYy"
      },
      "source": [
        "### 2.14.3 New processed review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcXY0eMChtTw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f0e72ec0-9a59-42d6-bd79-757cf6111b21"
      },
      "source": [
        "processed_review.select('filtered_ngrams').show(10, truncate=90)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------------+\n",
            "|                                                                           filtered_ngrams|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "|            [pop_sound, low_price, price_pop, pop_filter, low_price_pop, price_pop_filter]|\n",
            "|[be_double, double_screen, add_bonus, small_hint, old_grape, grape_candy, cannot_stop, ...|\n",
            "|[primary_job, pop_sound, noticeable_reduction, high_frequency, double_cloth, cloth_filt...|\n",
            "|[nice_windscreen, windscreen_protect, mxl_mic, prevent_pop, require_careful, careful_po...|\n",
            "|             [pop_filter, be_great, studio_filter, youre_record, record_vocal, get_record]|\n",
            "|[heavy_cord, gold_connector, connector_bass, bass_sound, sound_great, learn_last, last_...|\n",
            "|[have_use, use_monster, monster_cable, good_reason, lifetime_warranty, be_worth, simple...|\n",
            "|[buy_monster, monster_cable, pedal_board, be_use, high_end, end_planet, planet_wave, wa...|\n",
            "|[epiphone_sheraton, sheraton_ii, ii_monster, monster_cable, have_several, degree_plug, ...|\n",
            "|[monster_make, good_cable, lifetime_warranty, warranty_doesnt, line_series, work_great,...|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciCceJZH5NmN"
      },
      "source": [
        "## 2.15 Combine unigram and ngrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVNl50pI7U1S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e5f97af3-bea6-459d-b384-c9dcc7012190"
      },
      "source": [
        "from pyspark.sql.functions import concat\n",
        "\n",
        "processed_review = processed_review.withColumn('final', \n",
        "      concat(F.col('finished_unigrams'), F.col('filtered_ngrams')))\n",
        "\n",
        "processed_review.select('final').show(10, truncate=90)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------------+\n",
            "|                                                                                     final|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "|[much, write, exactly, suppose, filter, pop, sound, recordings, much, crisp, one, low, ...|\n",
            "|[product, exactly, quite, affordablei, realize, double, screen, arrive, even, well, exp...|\n",
            "|[primary, job, device, block, breath, would, otherwise, produce, pop, sound, allow, voi...|\n",
            "|[nice, windscreen, protect, mxl, mic, prevent, pop, thing, gooseneck, marginally, able,...|\n",
            "|[pop, filter, great, look, perform, like, studio, filter, youre, record, vocal, elimina...|\n",
            "|[good, buy, another, one, love, heavy, cord, gold, connector, bass, sound, great, learn...|\n",
            "|[use, monster, cable, year, good, reason, lifetime, warranty, worth, price, alone, simp...|\n",
            "|[use, cable, run, output, pedal, chain, input, fender, amp, buy, monster, cable, hook, ...|\n",
            "|[perfect, epiphone, sheraton, ii, monster, cable, well, construct, several, never, prob...|\n",
            "|[monster, make, good, cable, lifetime, warranty, doesnt, hurt, either, isnt, top, line,...|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OTK4DVHxcR0"
      },
      "source": [
        "# **Part 3: Vectorization of text tokens**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP4HlvFR5jXp"
      },
      "source": [
        "## 3.1 CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqGT4ss7r_w2"
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "countVectorizer = CountVectorizer(inputCol='final', outputCol='tf_features')\n",
        "tf_model = countVectorizer.fit(processed_review)\n",
        "processed_review = tf_model.transform(processed_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "217ZJrT76B2h"
      },
      "source": [
        "## 3.2 IDF (*inverse document frequency*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox3dEUoyx2Ss"
      },
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "\n",
        "idfizer = IDF(inputCol='tf_features', outputCol='tf_idf_features')\n",
        "idf_model = idfizer.fit(processed_review)\n",
        "processed_review = idf_model.transform(processed_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCQdJS0HZelD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "a0778a04-2434-46bc-e77a-2ebce8785cfc"
      },
      "source": [
        "processed_review.show(10, truncate=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|                    reviewText|             finished_unigrams|               finished_ngrams|                  finished_pos|           finished_pos_ngrams|               filtered_ngrams|                         final|                   tf_features|               tf_idf_features|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|Not much to write about her...|[much, write, exactly, supp...|[not, much, to, write, abou...|[RB, JJ, TO, VB, IN, RB, CC...|[RB, JJ, TO, VB, IN, RB, CC...|[pop_sound, low_price, pric...|[much, write, exactly, supp...|(137641,[2,3,4,11,13,18,25,...|(137641,[2,3,4,11,13,18,25,...|\n",
            "|The product does exactly as...|[product, exactly, quite, a...|[the, product, do, exactly,...|[DT, NN, VBP, RB, IN, PRP, ...|[DT, NN, VBP, RB, IN, PRP, ...|[be_double, double_screen, ...|[product, exactly, quite, a...|(137641,[0,3,4,8,11,13,20,4...|(137641,[0,3,4,8,11,13,20,4...|\n",
            "|The primary job of this dev...|[primary, job, device, bloc...|[the, primary, job, of, thi...|[DT, JJ, NN, IN, DT, NN, VB...|[DT, JJ, NN, IN, DT, NN, VB...|[primary_job, pop_sound, no...|[primary, job, device, bloc...|(137641,[2,17,20,23,34,61,6...|(137641,[2,17,20,23,34,61,6...|\n",
            "|Nice windscreen protects my...|[nice, windscreen, protect,...|[nice, windscreen, protect,...|[JJ, NN, NN, NNP, NN, JJ, C...|[JJ, NN, NN, NNP, NN, JJ, C...|[nice_windscreen, windscree...|[nice, windscreen, protect,...|(137641,[29,40,44,62,245,36...|(137641,[29,40,44,62,245,36...|\n",
            "|This pop filter is great. I...|[pop, filter, great, look, ...|[this, pop, filter, be, gre...|[DT, NN, NN, VB, JJ, PRP, V...|[DT, NN, NN, VB, JJ, PRP, V...|[pop_filter, be_great, stud...|[pop, filter, great, look, ...|(137641,[7,8,9,24,86,108,13...|(137641,[7,8,9,24,86,108,13...|\n",
            "|So good that I bought anoth...|[good, buy, another, one, l...|[so, good, that, i, buy, an...|[RB, JJ, IN, NNP, VB, DT, C...|[RB, JJ, IN, NNP, VB, DT, C...|[heavy_cord, gold_connector...|[good, buy, another, one, l...|(137641,[2,3,5,9,11,13,59,6...|(137641,[2,3,5,9,11,13,59,6...|\n",
            "|I have used monster cables ...|[use, monster, cable, year,...|[i, have, use, monster, cab...|[NNP, VBP, NN, NN, NN, IN, ...|[NNP, VBP, NN, NN, NN, IN, ...|[have_use, use_monster, mon...|[use, monster, cable, year,...|(137641,[0,5,7,18,33,50,130...|(137641,[0,5,7,18,33,50,130...|\n",
            "|I now use this cable to run...|[use, cable, run, output, p...|[i, now, use, this, cable, ...|[NNP, RB, VBP, DT, NN, TO, ...|[NNP, RB, VBP, DT, NN, TO, ...|[buy_monster, monster_cable...|[use, cable, run, output, p...|(137641,[0,1,3,7,10,13,16,1...|(137641,[0,1,3,7,10,13,16,1...|\n",
            "|Perfect for my Epiphone She...|[perfect, epiphone, sherato...|[perfect, for, i, epiphone,...|[JJ, IN, NNP, NN, NN, NN, N...|[JJ, IN, NNP, NN, NN, NN, N...|[epiphone_sheraton, sherato...|[perfect, epiphone, sherato...|(137641,[3,4,7,33,36,50,80,...|(137641,[3,4,7,33,36,50,80,...|\n",
            "|Monster makes the best cabl...|[monster, make, good, cable...|[monster, make, the, good, ...|[NN, NN, DT, JJ, NN, CC, DT...|[NN, NN, DT, JJ, NN, CC, DT...|[monster_make, good_cable, ...|[monster, make, good, cable...|(137641,[1,5,9,11,12,21,27,...|(137641,[1,5,9,11,12,21,27,...|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezlCICGwzvQu"
      },
      "source": [
        "# **Part 4: Latent Dirichlet Allocation algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kelkPspY6okR"
      },
      "source": [
        "## 4.1 Train Topic Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID3lf4GjzxJq"
      },
      "source": [
        "from pyspark.ml.clustering import LDA\n",
        "\n",
        "num_topics = data_params[2]\n",
        "max_iter = 10\n",
        "\n",
        "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
        "lda_model = lda.fit(processed_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKbQhfaSt46c"
      },
      "source": [
        "## 4.2 Topic size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ0q-Y9SuHB2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "42a18caa-6279-405b-bc32-394e22614121"
      },
      "source": [
        "import numpy as np\n",
        "def vect_argmax(vect):\n",
        "  arra = vect.toArray()\n",
        "  max_pos = np.argmax(arra)\n",
        "  return int(max_pos)\n",
        "\n",
        "udf_argmax = F.udf(vect_argmax, T.IntegerType())\n",
        "\n",
        "processed_review = lda_model.transform(processed_review)\n",
        "processed_review = processed_review.withColumn('topic#', udf_argmax(F.col('topicDistribution')))\n",
        "processed_review.show(10, truncate=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------+\n",
            "|                    reviewText|             finished_unigrams|               finished_ngrams|                  finished_pos|           finished_pos_ngrams|               filtered_ngrams|                         final|                   tf_features|               tf_idf_features|             topicDistribution|topic#|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------+\n",
            "|Not much to write about her...|[much, write, exactly, supp...|[not, much, to, write, abou...|[RB, JJ, TO, VB, IN, RB, CC...|[RB, JJ, TO, VB, IN, RB, CC...|[pop_sound, low_price, pric...|[much, write, exactly, supp...|(137641,[2,3,4,11,13,18,25,...|(137641,[2,3,4,11,13,18,25,...|[0.001401580013355942,0.001...|     2|\n",
            "|The product does exactly as...|[product, exactly, quite, a...|[the, product, do, exactly,...|[DT, NN, VBP, RB, IN, PRP, ...|[DT, NN, VBP, RB, IN, PRP, ...|[be_double, double_screen, ...|[product, exactly, quite, a...|(137641,[0,3,4,8,11,13,20,4...|(137641,[0,3,4,8,11,13,20,4...|[0.362125885669581,4.249108...|     0|\n",
            "|The primary job of this dev...|[primary, job, device, bloc...|[the, primary, job, of, thi...|[DT, JJ, NN, IN, DT, NN, VB...|[DT, JJ, NN, IN, DT, NN, VB...|[primary_job, pop_sound, no...|[primary, job, device, bloc...|(137641,[2,17,20,23,34,61,6...|(137641,[2,17,20,23,34,61,6...|[0.13851155662377973,4.3261...|     2|\n",
            "|Nice windscreen protects my...|[nice, windscreen, protect,...|[nice, windscreen, protect,...|[JJ, NN, NN, NNP, NN, JJ, C...|[JJ, NN, NN, NNP, NN, JJ, C...|[nice_windscreen, windscree...|[nice, windscreen, protect,...|(137641,[29,40,44,62,245,36...|(137641,[29,40,44,62,245,36...|[9.757730517981431E-4,8.200...|     3|\n",
            "|This pop filter is great. I...|[pop, filter, great, look, ...|[this, pop, filter, be, gre...|[DT, NN, NN, VB, JJ, PRP, V...|[DT, NN, NN, VB, JJ, PRP, V...|[pop_filter, be_great, stud...|[pop, filter, great, look, ...|(137641,[7,8,9,24,86,108,13...|(137641,[7,8,9,24,86,108,13...|[0.0017426935863485568,0.00...|     2|\n",
            "|So good that I bought anoth...|[good, buy, another, one, l...|[so, good, that, i, buy, an...|[RB, JJ, IN, NNP, VB, DT, C...|[RB, JJ, IN, NNP, VB, DT, C...|[heavy_cord, gold_connector...|[good, buy, another, one, l...|(137641,[2,3,5,9,11,13,59,6...|(137641,[2,3,5,9,11,13,59,6...|[0.0010003046854827364,8.42...|     2|\n",
            "|I have used monster cables ...|[use, monster, cable, year,...|[i, have, use, monster, cab...|[NNP, VBP, NN, NN, NN, IN, ...|[NNP, VBP, NN, NN, NN, IN, ...|[have_use, use_monster, mon...|[use, monster, cable, year,...|(137641,[0,5,7,18,33,50,130...|(137641,[0,5,7,18,33,50,130...|[0.0011420226324079454,9.60...|     2|\n",
            "|I now use this cable to run...|[use, cable, run, output, p...|[i, now, use, this, cable, ...|[NNP, RB, VBP, DT, NN, TO, ...|[NNP, RB, VBP, DT, NN, TO, ...|[buy_monster, monster_cable...|[use, cable, run, output, p...|(137641,[0,1,3,7,10,13,16,1...|(137641,[0,1,3,7,10,13,16,1...|[3.169088809224642E-4,0.185...|     2|\n",
            "|Perfect for my Epiphone She...|[perfect, epiphone, sherato...|[perfect, for, i, epiphone,...|[JJ, IN, NNP, NN, NN, NN, N...|[JJ, IN, NNP, NN, NN, NN, N...|[epiphone_sheraton, sherato...|[perfect, epiphone, sherato...|(137641,[3,4,7,33,36,50,80,...|(137641,[3,4,7,33,36,50,80,...|[0.5958152808563045,0.00110...|     0|\n",
            "|Monster makes the best cabl...|[monster, make, good, cable...|[monster, make, the, good, ...|[NN, NN, DT, JJ, NN, CC, DT...|[NN, NN, DT, JJ, NN, CC, DT...|[monster_make, good_cable, ...|[monster, make, good, cable...|(137641,[1,5,9,11,12,21,27,...|(137641,[1,5,9,11,12,21,27,...|[0.0010338091106216398,8.71...|     2|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCXoRoEVv-Xv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4f020dba-7800-4959-9579-53105db0f99c"
      },
      "source": [
        "processed_review.groupBy('topic#').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|topic#|count|\n",
            "+------+-----+\n",
            "|     1|  305|\n",
            "|     3|  339|\n",
            "|     5|  777|\n",
            "|     4|  325|\n",
            "|     2| 5681|\n",
            "|     0| 2827|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GllCV-hw7fgL"
      },
      "source": [
        "## 4.3 Top words that define topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxbhwXnQ0dEa"
      },
      "source": [
        "vocab = tf_model.vocabulary\n",
        "\n",
        "def get_words(token_list):\n",
        "     return [vocab[token_id] for token_id in token_list]\n",
        "       \n",
        "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhsk4J5p0lOm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "736ac4c6-468b-4dbd-9854-5993b1af998e"
      },
      "source": [
        "num_top_words = 10\n",
        "\n",
        "topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
        "topics.select('topic', 'topicWords').show(truncate=90)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------------------------------------------------------------------+\n",
            "|topic|                                                                      topicWords|\n",
            "+-----+--------------------------------------------------------------------------------+\n",
            "|    0|                [string, guitar, tuner, pick, case, tune, capo, one, good, time]|\n",
            "|    1|                   [hd, edirol, pedal, recorder, cable, sound, h, hn, cry, zoom]|\n",
            "|    2|                    [pedal, sound, amp, use, one, get, cable, guitar, mic, tone]|\n",
            "|    3|            [amp, pick, kyser, sound, use, return, pickup, seller, amazon, capo]|\n",
            "|    4|            [sweep, pick, great_pick, mic, string, tin, use, sound, speed, well]|\n",
            "|    5|[strap, lock, guitar_strap, pick, guitar, strap_lock, slide, bag, dunlop, screw]|\n",
            "+-----+--------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
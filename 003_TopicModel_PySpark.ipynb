{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BIszqyp8lzSU",
        "IdZPmaFPtwyq",
        "9hHCLbrpfSqO",
        "Pa4UrSFFvizm",
        "_Oxvz01vfaq6",
        "-OTK4DVHxcR0",
        "ezlCICGwzvQu"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfAJhrgFo5Tv"
      },
      "source": [
        "# **Topic Modeling with PySpark and Spark NLP**\n",
        "Topic Modelling is a statistical approach for data modelling that helps in discovering underlying topics that are present in the collection of documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ9ZF9pQqW2X"
      },
      "source": [
        "In this project we built the NLP pipeline with Spark NLP and trained a topic model with PySpark. (see [here](https://github.com/maobedkova/TopicModelling_PySpark_SparkNLP/blob/master/Topic_Modelling_with_PySpark_and_Spark_NLP.ipynb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIszqyp8lzSU"
      },
      "source": [
        "# **Part 0: PySpark Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## update apt-get\n",
        "!apt-get update\n",
        "\n",
        "## Install java\n",
        "import os\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!java -version\n",
        "\n",
        "## Install pyspark\n",
        "!pip install -q pyspark==3.3.0\n",
        "\n",
        "## Install Spark NLP\n",
        "!pip install -q spark-nlp==4.2.4\n",
        "\n",
        "## start the Spark session through Spark NLP\n",
        "import sparknlp\n",
        "spark = sparknlp.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxq-09XdFIbM",
        "outputId": "8df79f2e-39a5-4a56-83e0-3522c0449a36"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Waiting for headers] [1 I\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Waiting for headers] [Con\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Waiting for headers] [Con\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,004 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,269 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,081 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,342 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,038 kB in 3s (1,694 kB/s)\n",
            "Reading package lists... Done\n",
            "openjdk version \"11.0.20.1\" 2023-08-24\n",
            "OpenJDK Runtime Environment (build 11.0.20.1+1-post-Ubuntu-0ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.20.1+1-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.4/448.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPmFVedSA68v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "7d7576b0-42c5-4f5b-c339-600a014e3431"
      },
      "source": [
        "# Install pyspark\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark # used to locate the spark in the system\n",
        "\n",
        "import findspark\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "findspark.init()\n",
        "\n",
        "# spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Install pyspark\n",
        "!pip install pyspark==2.4.5\n",
        "\n",
        "## Install Spark NLP\n",
        "!pip install spark-nlp==2.4.5\n",
        "\n",
        "## Install nltk\n",
        "#!pip install nltk\n",
        "\n",
        "## start the Spark session through Spark NLP\n",
        "import sparknlp\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n",
            "Requirement already satisfied: pyspark==2.4.5 in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark==2.4.5) (0.10.7)\n",
            "Requirement already satisfied: spark-nlp==2.4.5 in /usr/local/lib/python3.6/dist-packages (2.4.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E9V97lh_LBj"
      },
      "source": [
        "# **Part 1: Data Loading**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfgD9jhRrFEF"
      },
      "source": [
        "In this project, I analyzed three datasets which from Kaggle:\n",
        "- [Amazon Musical Instruments Review](https://www.kaggle.com/eswarchandt/amazon-music-reviews)\n",
        "- [A Million News Headlines](https://www.kaggle.com/therohk/million-headlines)\n",
        "- [Amazon Watch Review]\n",
        "- [Youtube PetChannel Review]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qRFqVCfo_HY"
      },
      "source": [
        "## 1.1 Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sga628Xqypd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f437751-57a5-4338-f916-f65947194eb2"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('ggdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ggdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdZPmaFPtwyq"
      },
      "source": [
        "## 1.2 Read data from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19uyI_8dAd3j"
      },
      "source": [
        "datasets = {'amazonMusic': ['ggdrive/MyDrive/Data/SparkNlp/Musical_Instruments_5.json',\n",
        "                            'reviewText', 6],\n",
        "            'abcnews': ['ggdrive/MyDrive/Data/SparkNlp/abcnews-date-text.csv',\n",
        "                        'headline_text', 20],\n",
        "            'amazonWatch': ['ggdrive/MyDrive/Data/watch_reviews.tsv',\n",
        "                            'review_body', 6]}\n",
        "\n",
        "data_nm = ['amazonMusic', 'abcnews', 'amazonWatch'][0]\n",
        "data_params = datasets[data_nm]\n",
        "\n",
        "if data_nm == 'amazonMusic':\n",
        "  data = spark.read.json(data_params[0])\n",
        "elif data_nm == 'abcnews':\n",
        "  data = spark.read.option('header', 'true')\\\n",
        "         .option('mode', 'DROPMALFORMED')\\\n",
        "         .option('inferSchema', True)\\\n",
        "         .csv(data_params[0])\n",
        "elif data_nm == 'amazonWatch':\n",
        "  data = spark.read.csv(data_params[0], sep=r'\\t', header=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BohpGAxPuezM"
      },
      "source": [
        "## 1.3 Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_4_zyfNBlzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0d9cd3-1d2d-40c6-b5eb-abc56ed46b2d"
      },
      "source": [
        "# spark dataframe schema\n",
        "data.printSchema()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- asin: string (nullable = true)\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- overall: double (nullable = true)\n",
            " |-- reviewText: string (nullable = true)\n",
            " |-- reviewTime: string (nullable = true)\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- reviewerName: string (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- unixReviewTime: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBgMDyVQDU9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac62e3d-363b-49dd-e21f-c7c01ef33d64"
      },
      "source": [
        "# how the data looks like\n",
        "data.show(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
            "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "|1384719342|  [0, 0]|    5.0|Not much to write...|02 28, 2014|A2IBPI20UZIR0U|cassandra tu \"Yea...|                good|    1393545600|\n",
            "|1384719342|[13, 14]|    5.0|The product does ...|03 16, 2013|A14VAT5EAX3D9S|                Jake|                Jake|    1363392000|\n",
            "|1384719342|  [1, 1]|    5.0|The primary job o...|08 28, 2013|A195EZSQDW3E21|Rick Bennette \"Ri...|It Does The Job Well|    1377648000|\n",
            "|1384719342|  [0, 0]|    5.0|Nice windscreen p...|02 14, 2014|A2C00NNG1ZQQG2|RustyBill \"Sunday...|GOOD WINDSCREEN F...|    1392336000|\n",
            "|1384719342|  [0, 0]|    5.0|This pop filter i...|02 21, 2014| A94QU4C90B1AX|       SEAN MASLANKA|No more pops when...|    1392940800|\n",
            "|B00004Y2UT|  [0, 0]|    5.0|So good that I bo...|12 21, 2012|A2A039TZMZHH9Y| Bill Lewey \"blewey\"|      The Best Cable|    1356048000|\n",
            "|B00004Y2UT|  [0, 0]|    5.0|I have used monst...|01 19, 2014|A1UPZM995ZAH90|               Brian|Monster Standard ...|    1390089600|\n",
            "|B00004Y2UT|  [0, 0]|    3.0|I now use this ca...|11 16, 2012| AJNFQI3YR6XJ5|   Fender Guy \"Rick\"|Didn't fit my 199...|    1353024000|\n",
            "|B00004Y2UT|  [0, 0]|    5.0|Perfect for my Ep...| 07 6, 2008|A3M1PLEYNDEYO8|     G. Thomas \"Tom\"|         Great cable|    1215302400|\n",
            "|B00004Y2UT|  [0, 0]|    5.0|Monster makes the...| 01 8, 2014| AMNTZU1YQN1TH|         Kurt Robair|Best Instrument C...|    1389139200|\n",
            "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1YbHHIKEnrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56b046a-e119-41b3-e9c4-432ac87fa65b"
      },
      "source": [
        "# the number of rows\n",
        "print(f'Totally, we have {data.count()} rows of data.')\n",
        "\n",
        "# target column\n",
        "text_col = data_params[1]\n",
        "print(f'For column \"{text_col}\", we have {data.select(text_col).distinct().count()} rows of distinct values')\n",
        "review_text = data.select(text_col).na.drop()#.dropDuplicates()\n",
        "\n",
        "#review_text = spark.createDataFrame(review_text.collect()[:1000])\n",
        "#review_text = review_text.sample(withReplacement=False, fraction=0.01, seed=2020)\n",
        "\n",
        "print(f'After clean-up and sampling, we have {review_text.count()} rows of {text_col} data:')\n",
        "review_text.show(10, truncate=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totally, we have 10261 rows of data.\n",
            "For column \"reviewText\", we have 10255 rows of distinct values\n",
            "After clean-up and sampling, we have 10261 rows of reviewText data:\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "|                                                                                          reviewText|\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "|Not much to write about here, but it does exactly what it's supposed to. filters out the pop soun...|\n",
            "|The product does exactly as it should and is quite affordable.I did not realized it was double sc...|\n",
            "|The primary job of this device is to block the breath that would otherwise produce a popping soun...|\n",
            "|Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck is only m...|\n",
            "|This pop filter is great. It looks and performs like a studio filter. If you're recording vocals ...|\n",
            "|So good that I bought another one.  Love the heavy cord and gold connectors.  Bass sounds great. ...|\n",
            "|I have used monster cables for years, and with good reason. The lifetime warranty is worth the pr...|\n",
            "|I now use this cable to run from the output of my pedal chain to the input of my Fender Amp. Afte...|\n",
            "|Perfect for my Epiphone Sheraton II.  Monster cables are well constructed.  I have several and ne...|\n",
            "|Monster makes the best cables and a lifetime warranty doesnt hurt either. This isnt their top of ...|\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkMWsrcoQyH2"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "#review_text.select(F.count(F.when(F.col(text_col).isNull() | F.isnan(text_col), text_col)).alias(text_col)).show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hHCLbrpfSqO"
      },
      "source": [
        "# **Part 2: Spark NLP pipeline** ([annotators](https://nlp.johnsnowlabs.com/docs/en/annotators))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PjxUquwv83c"
      },
      "source": [
        "## 2.1 DocumentAssembler (see [here](https://nlp.johnsnowlabs.com/docs/en/transformers#documentassembler-getting-data-in))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwOdzQ_PAJi0"
      },
      "source": [
        "from sparknlp.base import DocumentAssembler\n",
        "\n",
        "documentAssembler = DocumentAssembler() \\\n",
        "     .setInputCol(text_col) \\\n",
        "     .setOutputCol('document')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facUm7iMwUKZ"
      },
      "source": [
        "## 2.2 Tokenizer (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGOLmEzJDCYW"
      },
      "source": [
        "from sparknlp.annotator import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "     .setInputCols(['document']) \\\n",
        "     .setOutputCol('tokenized')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA98q-HCxVjb"
      },
      "source": [
        "## 2.3 Normalizer (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#normalizer))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTuQv1VXD8xu"
      },
      "source": [
        "from sparknlp.annotator import Normalizer\n",
        "\n",
        "normalizer = Normalizer() \\\n",
        "     .setInputCols(['tokenized']) \\\n",
        "     .setOutputCol('normalized') \\\n",
        "     .setLowercase(True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80FaYj0axg1r"
      },
      "source": [
        "## 2.4 LemmatizerModel (see [here](https://nlp.johnsnowlabs.com/docs/en/models#english---models))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1lvJInOEEAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc34db0-5989-40b9-b039-4465ef50ef29"
      },
      "source": [
        "from sparknlp.annotator import LemmatizerModel\n",
        "\n",
        "lemmatizer = LemmatizerModel.pretrained() \\\n",
        "     .setInputCols(['normalized']) \\\n",
        "     .setOutputCol('lemmatized')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKDZh-kkybKt"
      },
      "source": [
        "## 2.5 StopWordsCleaner (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#stopwordscleaner))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um9iOifSft2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9586a745-8514-42fd-c3af-5d13102f4ea1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "eng_stopwords = stopwords.words('english')\n",
        "\n",
        "######\n",
        "from sparknlp.annotator import StopWordsCleaner\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner() \\\n",
        "     .setInputCols(['lemmatized']) \\\n",
        "     .setOutputCol('unigrams') \\\n",
        "     .setStopWords(eng_stopwords)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW87_1g2yr3-"
      },
      "source": [
        "## 2.6 NGramGenerator (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#ngramgenerator))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsftJKunZO84"
      },
      "source": [
        "from sparknlp.annotator import NGramGenerator\n",
        "\n",
        "ngrammer = NGramGenerator() \\\n",
        "    .setInputCols(['lemmatized']) \\\n",
        "    .setOutputCol('ngrams') \\\n",
        "    .setN(3) \\\n",
        "    .setEnableCumulative(True) \\\n",
        "    .setDelimiter('_')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymL8JUPrzV0R"
      },
      "source": [
        "## 2.7 PerceptronModel (see [here](https://nlp.johnsnowlabs.com/docs/en/annotators#postagger)) for POS (Part Of Speech)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilOwKkC20Xe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad77970-2231-4dc4-c500-40dd5e29edd5"
      },
      "source": [
        "from sparknlp.annotator import PerceptronModel\n",
        "\n",
        "pos_tagger = PerceptronModel.pretrained('pos_anc') \\\n",
        "    .setInputCols(['document', 'lemmatized']) \\\n",
        "    .setOutputCol('pos')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl6Xs_zE0Fc8"
      },
      "source": [
        "## 2.8 Finisher (see [here](https://nlp.johnsnowlabs.com/docs/en/transformers#finisher))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3eYHx-KrDxU"
      },
      "source": [
        "from sparknlp.base import Finisher\n",
        "\n",
        "finisher = Finisher() \\\n",
        "     .setInputCols(['unigrams', 'ngrams', 'pos'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP-kJKHQ0T8e"
      },
      "source": [
        "## 2.9 Basic NLP Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo4ixwfsrMPh"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline() \\\n",
        "     .setStages([documentAssembler,\n",
        "                 tokenizer,\n",
        "                 normalizer,\n",
        "                 lemmatizer,\n",
        "                 stopwords_cleaner,\n",
        "                 ngrammer,\n",
        "                 pos_tagger,\n",
        "                 finisher])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yXiHvEE0gYx"
      },
      "source": [
        "## 2.10 Fit and transform review_text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCkceTwhrOf0"
      },
      "source": [
        "processed_review = pipeline.fit(review_text).transform(review_text)\n",
        "#processed_review.select(*(F.count(F.when(F.size(F.col(c)) == 0, c)).alias(c)\\\n",
        "#                          for c in processed_review.columns[1:])).show()\n",
        "\n",
        "processed_review = processed_review.filter(F.size(F.col('finished_unigrams')) > 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7ovKGdr0p6J"
      },
      "source": [
        "## 2.11 processed_review looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-vuMJZD9Lwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb2175f-a4b9-4428-b7b0-4621b55210a7"
      },
      "source": [
        "processed_review.show(10, truncate=30)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|                    reviewText|             finished_unigrams|               finished_ngrams|                  finished_pos|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|Not much to write about her...|[much, write, exactly, supp...|[not, much, to, write, abou...|[RB, JJ, TO, VB, IN, RB, CC...|\n",
            "|The product does exactly as...|[product, exactly, quite, a...|[the, product, do, exactly,...|[DT, NN, VBP, RB, IN, PRP, ...|\n",
            "|The primary job of this dev...|[primary, job, device, bloc...|[the, primary, job, of, thi...|[DT, JJ, NN, IN, DT, NN, VB...|\n",
            "|Nice windscreen protects my...|[nice, windscreen, protect,...|[nice, windscreen, protect,...|[JJ, NN, NN, NNP, NN, JJ, C...|\n",
            "|This pop filter is great. I...|[pop, filter, great, look, ...|[this, pop, filter, be, gre...|[DT, NN, NN, VB, JJ, PRP, V...|\n",
            "|So good that I bought anoth...|[good, buy, another, one, l...|[so, good, that, i, buy, an...|[RB, JJ, IN, NNP, VB, DT, C...|\n",
            "|I have used monster cables ...|[use, monster, cable, year,...|[i, have, use, monster, cab...|[NNP, VBP, NN, NN, NN, IN, ...|\n",
            "|I now use this cable to run...|[use, cable, run, output, p...|[i, now, use, this, cable, ...|[NNP, RB, VBP, DT, NN, TO, ...|\n",
            "|Perfect for my Epiphone She...|[perfect, epiphone, sherato...|[perfect, for, i, epiphone,...|[JJ, IN, NNP, NN, NN, NN, N...|\n",
            "|Monster makes the best cabl...|[monster, make, good, cable...|[monster, make, the, good, ...|[NN, NN, DT, JJ, NN, CC, DT...|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FnnKmIf2Ssc"
      },
      "source": [
        "## 2.12 POS tags of ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUEAaOogCve2"
      },
      "source": [
        "### 2.12.1 Join pos of unigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbPpOs8ndGE9"
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import types as T\n",
        "\n",
        "udf_join_arr = F.udf(lambda x: ' '.join(x), T.StringType())\n",
        "processed_review  = processed_review.withColumn('finished_pos', udf_join_arr(F.col('finished_pos')))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G50ES8tcC8FQ"
      },
      "source": [
        "### 2.12.2 Transform joined pos into annotation format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKEpmfoba6M"
      },
      "source": [
        "pos_documentAssembler = DocumentAssembler() \\\n",
        "     .setInputCol('finished_pos') \\\n",
        "     .setOutputCol('pos_document')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smZ6-1dz2uf3"
      },
      "source": [
        "### 2.12.3 pos_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyZdZ7S8aGZ9"
      },
      "source": [
        "pos_tokenizer = Tokenizer() \\\n",
        "     .setInputCols(['pos_document']) \\\n",
        "     .setOutputCol('pos')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8kJmdm52w-M"
      },
      "source": [
        "### 2.12.4 NGramGenerator of pos tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QnL0zwrW_w-"
      },
      "source": [
        "pos_ngrammer = NGramGenerator() \\\n",
        "    .setInputCols(['pos']) \\\n",
        "    .setOutputCol('pos_ngrams') \\\n",
        "    .setN(3) \\\n",
        "    .setEnableCumulative(True) \\\n",
        "    .setDelimiter('_')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG3UTh0N23Yf"
      },
      "source": [
        "### 2.12.5 pos_finisher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiUGFlMHZqIZ"
      },
      "source": [
        "pos_finisher = Finisher() \\\n",
        "     .setInputCols(['pos', 'pos_ngrams'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSQ1XeNZ2--r"
      },
      "source": [
        "### 2.12.6 NLP pipeline for pos tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-AufeTzbYwM"
      },
      "source": [
        "pos_pipeline = Pipeline() \\\n",
        "     .setStages([pos_documentAssembler,\n",
        "                 pos_tokenizer,\n",
        "                 pos_ngrammer,\n",
        "                 pos_finisher])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxQJcpiA3EBg"
      },
      "source": [
        "### 2.12.7 Pipeline fit and transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kfpx2azbmJI"
      },
      "source": [
        "processed_review = pos_pipeline.fit(processed_review).transform(processed_review)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUbDHzkZ3JzH"
      },
      "source": [
        "### 2.12.8 New processed review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0dBA85zf3Sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a887f0c-a47b-4ae8-bdec-9f8f62432446"
      },
      "source": [
        "processed_review.show(10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|          reviewText|   finished_unigrams|     finished_ngrams|        finished_pos| finished_pos_ngrams|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Not much to write...|[much, write, exa...|[not, much, to, w...|[RB, JJ, TO, VB, ...|[RB, JJ, TO, VB, ...|\n",
            "|The product does ...|[product, exactly...|[the, product, do...|[DT, NN, VBP, RB,...|[DT, NN, VBP, RB,...|\n",
            "|The primary job o...|[primary, job, de...|[the, primary, jo...|[DT, JJ, NN, IN, ...|[DT, JJ, NN, IN, ...|\n",
            "|Nice windscreen p...|[nice, windscreen...|[nice, windscreen...|[JJ, NN, NN, NNP,...|[JJ, NN, NN, NNP,...|\n",
            "|This pop filter i...|[pop, filter, gre...|[this, pop, filte...|[DT, NN, NN, VB, ...|[DT, NN, NN, VB, ...|\n",
            "|So good that I bo...|[good, buy, anoth...|[so, good, that, ...|[RB, JJ, IN, NNP,...|[RB, JJ, IN, NNP,...|\n",
            "|I have used monst...|[use, monster, ca...|[i, have, use, mo...|[NNP, VBP, NN, NN...|[NNP, VBP, NN, NN...|\n",
            "|I now use this ca...|[use, cable, run,...|[i, now, use, thi...|[NNP, RB, VBP, DT...|[NNP, RB, VBP, DT...|\n",
            "|Perfect for my Ep...|[perfect, epiphon...|[perfect, for, i,...|[JJ, IN, NNP, NN,...|[JJ, IN, NNP, NN,...|\n",
            "|Monster makes the...|[monster, make, g...|[monster, make, t...|[NN, NN, DT, JJ, ...|[NN, NN, DT, JJ, ...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCXs_3yNfXbG"
      },
      "source": [
        "## 2.13 Filter messing pos tag combination for unigram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix2DZ3ALHkob"
      },
      "source": [
        "### 2.13.1 udf function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhhKK97NfEbd"
      },
      "source": [
        "def filter_pos(words, pos_tags):\n",
        "    return [word for word, pos in zip(words, pos_tags) ## not 1 : 1\n",
        "            if pos in ['JJ', 'NN', 'NNS', 'VB', 'VBP']]\n",
        "\n",
        "udf_filter_pos = F.udf(filter_pos, T.ArrayType(T.StringType()))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YveLNdrmm_nX"
      },
      "source": [
        "# Function to get rows at `rownums`\n",
        "def getrows(df, rownums=None):\n",
        "    return df.rdd.zipWithIndex()\\\n",
        "         .filter(lambda x: x[1] in rownums)\\\n",
        "         .map(lambda x: x[0])\n",
        "\n",
        "# Get rows at positions 0 and 2.\n",
        "#row02 = getrows(processed_review, rownums=[2]).collect()\n",
        "#for i in [1, 2, 3, 4]:\n",
        "#  print(len(row02[0][i]))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_hy63My3rrV"
      },
      "source": [
        "### 2.13.2 Filter unigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEx5CHyqfWeG"
      },
      "source": [
        "#processed_review = processed_review.withColumn('filtered_unigrams',\n",
        "#      udf_filter_pos(F.col('finished_unigrams'), F.col('finished_pos')))\n",
        "#processed_review.select('filtered_unigrams').show(10, truncate=90)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEDG4jfD4Rux"
      },
      "source": [
        "## 2.14 Filter out improper POS combinations of n-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0cOckO_I79f"
      },
      "source": [
        "### 2.14.1 udf function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJd-nLnxgd1g"
      },
      "source": [
        "def filter_pos_combs(words, pos_tags):\n",
        "    return [word for word, pos in zip(words, pos_tags)\n",
        "            if (len(pos.split('_')) == 2 and \\\n",
        "                pos.split('_')[0] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                 pos.split('_')[1] in ['JJ', 'NN', 'NNS']) \\\n",
        "            or (len(pos.split('_')) == 3 and \\\n",
        "                pos.split('_')[0] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                 pos.split('_')[1] in ['JJ', 'NN', 'NNS', 'VB', 'VBP'] and \\\n",
        "                  pos.split('_')[2] in ['NN', 'NNS'])]\n",
        "\n",
        "udf_filter_pos_combs = F.udf(filter_pos_combs, T.ArrayType(T.StringType()))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zjj8b9v425f"
      },
      "source": [
        "### 2.14.2 Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH1gNrz6giPU"
      },
      "source": [
        "processed_review = processed_review.withColumn('filtered_ngrams',\n",
        "    udf_filter_pos_combs(F.col('finished_ngrams'), F.col('finished_pos_ngrams')))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kA7epRY5HYy"
      },
      "source": [
        "### 2.14.3 New processed review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcXY0eMChtTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55733db0-18d2-47f5-b718-70ec836696dc"
      },
      "source": [
        "processed_review.select('filtered_ngrams').show(10, truncate=100)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------+\n",
            "|                                                                           filtered_ngrams|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "|            [pop_sound, low_price, price_pop, pop_filter, low_price_pop, price_pop_filter]|\n",
            "|[be_double, double_screen, add_bonus, small_hint, old_grape, grape_candy, cannot_stop, ...|\n",
            "|[primary_job, pop_sound, noticeable_reduction, high_frequency, double_cloth, cloth_filt...|\n",
            "|[nice_windscreen, windscreen_protect, mxl_mic, prevent_pop, require_careful, careful_po...|\n",
            "|             [pop_filter, be_great, studio_filter, youre_record, record_vocal, get_record]|\n",
            "|[heavy_cord, gold_connector, connector_bass, bass_sound, sound_great, learn_last, last_...|\n",
            "|[have_use, use_monster, monster_cable, good_reason, lifetime_warranty, be_worth, simple...|\n",
            "|[buy_monster, monster_cable, pedal_board, be_use, high_end, end_planet, planet_wave, wa...|\n",
            "|[epiphone_sheraton, sheraton_ii, ii_monster, monster_cable, have_several, degree_plug, ...|\n",
            "|[monster_make, good_cable, lifetime_warranty, warranty_doesnt, line_series, work_great,...|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciCceJZH5NmN"
      },
      "source": [
        "## 2.15 Combine unigram and ngrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVNl50pI7U1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad641566-3048-40f0-e48d-5d3c4ee357c9"
      },
      "source": [
        "from pyspark.sql.functions import concat\n",
        "\n",
        "processed_review = processed_review.withColumn('final',\n",
        "      concat(F.col('finished_unigrams'), F.col('filtered_ngrams')))\n",
        "\n",
        "processed_review.select('final').show(10, truncate=100)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------+\n",
            "|                                                                                     final|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "|[much, write, exactly, suppose, filter, pop, sound, recordings, much, crisp, one, low, ...|\n",
            "|[product, exactly, quite, affordablei, realize, double, screen, arrive, even, well, exp...|\n",
            "|[primary, job, device, block, breath, would, otherwise, produce, pop, sound, allow, voi...|\n",
            "|[nice, windscreen, protect, mxl, mic, prevent, pop, thing, gooseneck, marginally, able,...|\n",
            "|[pop, filter, great, look, perform, like, studio, filter, youre, record, vocal, elimina...|\n",
            "|[good, buy, another, one, love, heavy, cord, gold, connector, bass, sound, great, learn...|\n",
            "|[use, monster, cable, year, good, reason, lifetime, warranty, worth, price, alone, simp...|\n",
            "|[use, cable, run, output, pedal, chain, input, fender, amp, buy, monster, cable, hook, ...|\n",
            "|[perfect, epiphone, sheraton, ii, monster, cable, well, construct, several, never, prob...|\n",
            "|[monster, make, good, cable, lifetime, warranty, doesnt, hurt, either, isnt, top, line,...|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OTK4DVHxcR0"
      },
      "source": [
        "# **Part 3: Vectorization of text tokens**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP4HlvFR5jXp"
      },
      "source": [
        "## 3.1 CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqGT4ss7r_w2"
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "countVectorizer = CountVectorizer(inputCol='final', outputCol='tf_features')\n",
        "tf_model = countVectorizer.fit(processed_review)\n",
        "processed_review = tf_model.transform(processed_review)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "217ZJrT76B2h"
      },
      "source": [
        "## 3.2 IDF (*inverse document frequency*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox3dEUoyx2Ss"
      },
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "\n",
        "idfizer = IDF(inputCol='tf_features', outputCol='tf_idf_features')\n",
        "idf_model = idfizer.fit(processed_review)\n",
        "processed_review = idf_model.transform(processed_review)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCQdJS0HZelD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffa9361-dc7a-4980-b1e6-edc0e41f0279"
      },
      "source": [
        "processed_review.show(10, truncate=30)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|                    reviewText|             finished_unigrams|               finished_ngrams|                  finished_pos|           finished_pos_ngrams|               filtered_ngrams|                         final|                   tf_features|               tf_idf_features|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|Not much to write about her...|[much, write, exactly, supp...|[not, much, to, write, abou...|[RB, JJ, TO, VB, IN, RB, CC...|[RB, JJ, TO, VB, IN, RB, CC...|[pop_sound, low_price, pric...|[much, write, exactly, supp...|(137641,[2,3,4,11,13,18,25,...|(137641,[2,3,4,11,13,18,25,...|\n",
            "|The product does exactly as...|[product, exactly, quite, a...|[the, product, do, exactly,...|[DT, NN, VBP, RB, IN, PRP, ...|[DT, NN, VBP, RB, IN, PRP, ...|[be_double, double_screen, ...|[product, exactly, quite, a...|(137641,[0,3,4,8,11,13,20,4...|(137641,[0,3,4,8,11,13,20,4...|\n",
            "|The primary job of this dev...|[primary, job, device, bloc...|[the, primary, job, of, thi...|[DT, JJ, NN, IN, DT, NN, VB...|[DT, JJ, NN, IN, DT, NN, VB...|[primary_job, pop_sound, no...|[primary, job, device, bloc...|(137641,[2,17,20,23,34,61,6...|(137641,[2,17,20,23,34,61,6...|\n",
            "|Nice windscreen protects my...|[nice, windscreen, protect,...|[nice, windscreen, protect,...|[JJ, NN, NN, NNP, NN, JJ, C...|[JJ, NN, NN, NNP, NN, JJ, C...|[nice_windscreen, windscree...|[nice, windscreen, protect,...|(137641,[29,40,44,62,245,36...|(137641,[29,40,44,62,245,36...|\n",
            "|This pop filter is great. I...|[pop, filter, great, look, ...|[this, pop, filter, be, gre...|[DT, NN, NN, VB, JJ, PRP, V...|[DT, NN, NN, VB, JJ, PRP, V...|[pop_filter, be_great, stud...|[pop, filter, great, look, ...|(137641,[7,8,9,24,86,108,13...|(137641,[7,8,9,24,86,108,13...|\n",
            "|So good that I bought anoth...|[good, buy, another, one, l...|[so, good, that, i, buy, an...|[RB, JJ, IN, NNP, VB, DT, C...|[RB, JJ, IN, NNP, VB, DT, C...|[heavy_cord, gold_connector...|[good, buy, another, one, l...|(137641,[2,3,5,9,11,13,59,6...|(137641,[2,3,5,9,11,13,59,6...|\n",
            "|I have used monster cables ...|[use, monster, cable, year,...|[i, have, use, monster, cab...|[NNP, VBP, NN, NN, NN, IN, ...|[NNP, VBP, NN, NN, NN, IN, ...|[have_use, use_monster, mon...|[use, monster, cable, year,...|(137641,[0,5,7,18,33,50,130...|(137641,[0,5,7,18,33,50,130...|\n",
            "|I now use this cable to run...|[use, cable, run, output, p...|[i, now, use, this, cable, ...|[NNP, RB, VBP, DT, NN, TO, ...|[NNP, RB, VBP, DT, NN, TO, ...|[buy_monster, monster_cable...|[use, cable, run, output, p...|(137641,[0,1,3,7,10,13,16,1...|(137641,[0,1,3,7,10,13,16,1...|\n",
            "|Perfect for my Epiphone She...|[perfect, epiphone, sherato...|[perfect, for, i, epiphone,...|[JJ, IN, NNP, NN, NN, NN, N...|[JJ, IN, NNP, NN, NN, NN, N...|[epiphone_sheraton, sherato...|[perfect, epiphone, sherato...|(137641,[3,4,7,33,36,50,80,...|(137641,[3,4,7,33,36,50,80,...|\n",
            "|Monster makes the best cabl...|[monster, make, good, cable...|[monster, make, the, good, ...|[NN, NN, DT, JJ, NN, CC, DT...|[NN, NN, DT, JJ, NN, CC, DT...|[monster_make, good_cable, ...|[monster, make, good, cable...|(137641,[1,5,9,11,12,21,27,...|(137641,[1,5,9,11,12,21,27,...|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezlCICGwzvQu"
      },
      "source": [
        "# **Part 4: Latent Dirichlet Allocation algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kelkPspY6okR"
      },
      "source": [
        "## 4.1 Train Topic Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID3lf4GjzxJq"
      },
      "source": [
        "from pyspark.ml.clustering import LDA\n",
        "\n",
        "num_topics = data_params[2]\n",
        "max_iter = 10\n",
        "\n",
        "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
        "lda_model = lda.fit(processed_review)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKbQhfaSt46c"
      },
      "source": [
        "## 4.2 Topic size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ0q-Y9SuHB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9fd74f-2c17-4283-8034-6fb8aa3384bf"
      },
      "source": [
        "import numpy as np\n",
        "def vect_argmax(vect):\n",
        "  arra = vect.toArray()\n",
        "  max_pos = np.argmax(arra)\n",
        "  return int(max_pos)\n",
        "\n",
        "udf_argmax = F.udf(vect_argmax, T.IntegerType())\n",
        "\n",
        "processed_review = lda_model.transform(processed_review)\n",
        "processed_review = processed_review.withColumn('topic#', udf_argmax(F.col('topicDistribution')))\n",
        "processed_review.show(10, truncate=30)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------+\n",
            "|                    reviewText|             finished_unigrams|               finished_ngrams|                  finished_pos|           finished_pos_ngrams|               filtered_ngrams|                         final|                   tf_features|               tf_idf_features|             topicDistribution|topic#|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------+\n",
            "|Not much to write about her...|[much, write, exactly, supp...|[not, much, to, write, abou...|[RB, JJ, TO, VB, IN, RB, CC...|[RB, JJ, TO, VB, IN, RB, CC...|[pop_sound, low_price, pric...|[much, write, exactly, supp...|(137641,[2,3,4,11,13,18,25,...|(137641,[2,3,4,11,13,18,25,...|[0.9938467328803339,0.00115...|     0|\n",
            "|The product does exactly as...|[product, exactly, quite, a...|[the, product, do, exactly,...|[DT, NN, VBP, RB, IN, PRP, ...|[DT, NN, VBP, RB, IN, PRP, ...|[be_double, double_screen, ...|[product, exactly, quite, a...|(137641,[0,3,4,8,11,13,20,4...|(137641,[0,3,4,8,11,13,20,4...|[0.3490553865170284,4.13374...|     5|\n",
            "|The primary job of this dev...|[primary, job, device, bloc...|[the, primary, job, of, thi...|[DT, JJ, NN, IN, DT, NN, VB...|[DT, JJ, NN, IN, DT, NN, VB...|[primary_job, pop_sound, no...|[primary, job, device, bloc...|(137641,[2,17,20,23,34,61,6...|(137641,[2,17,20,23,34,61,6...|[0.9977518111266305,4.21134...|     0|\n",
            "|Nice windscreen protects my...|[nice, windscreen, protect,...|[nice, windscreen, protect,...|[JJ, NN, NN, NNP, NN, JJ, C...|[JJ, NN, NN, NNP, NN, JJ, C...|[nice_windscreen, windscree...|[nice, windscreen, protect,...|(137641,[29,40,44,62,245,36...|(137641,[29,40,44,62,245,36...|[0.5425466922675276,0.35146...|     0|\n",
            "|This pop filter is great. I...|[pop, filter, great, look, ...|[this, pop, filter, be, gre...|[DT, NN, NN, VB, JJ, PRP, V...|[DT, NN, NN, VB, JJ, PRP, V...|[pop_filter, be_great, stud...|[pop, filter, great, look, ...|(137641,[7,8,9,24,86,108,13...|(137641,[7,8,9,24,86,108,13...|[0.9923163460383416,0.00143...|     0|\n",
            "|So good that I bought anoth...|[good, buy, another, one, l...|[so, good, that, i, buy, an...|[RB, JJ, IN, NNP, VB, DT, C...|[RB, JJ, IN, NNP, VB, DT, C...|[heavy_cord, gold_connector...|[good, buy, another, one, l...|(137641,[2,3,5,9,11,13,59,6...|(137641,[2,3,5,9,11,13,59,6...|[0.8231977304625768,8.20964...|     0|\n",
            "|I have used monster cables ...|[use, monster, cable, year,...|[i, have, use, monster, cab...|[NNP, VBP, NN, NN, NN, IN, ...|[NNP, VBP, NN, NN, NN, IN, ...|[have_use, use_monster, mon...|[use, monster, cable, year,...|(137641,[0,5,7,18,33,50,130...|(137641,[0,5,7,18,33,50,130...|[0.9950040176242464,9.35802...|     0|\n",
            "|I now use this cable to run...|[use, cable, run, output, p...|[i, now, use, this, cable, ...|[NNP, RB, VBP, DT, NN, TO, ...|[NNP, RB, VBP, DT, NN, TO, ...|[buy_monster, monster_cable...|[use, cable, run, output, p...|(137641,[0,1,3,7,10,13,16,1...|(137641,[0,1,3,7,10,13,16,1...|[0.7388804808670313,0.16568...|     0|\n",
            "|Perfect for my Epiphone She...|[perfect, epiphone, sherato...|[perfect, for, i, epiphone,...|[JJ, IN, NNP, NN, NN, NN, N...|[JJ, IN, NNP, NN, NN, NN, N...|[epiphone_sheraton, sherato...|[perfect, epiphone, sherato...|(137641,[3,4,7,33,36,50,80,...|(137641,[3,4,7,33,36,50,80,...|[0.8816452199591808,0.00107...|     0|\n",
            "|Monster makes the best cabl...|[monster, make, good, cable...|[monster, make, the, good, ...|[NN, NN, DT, JJ, NN, CC, DT...|[NN, NN, DT, JJ, NN, CC, DT...|[monster_make, good_cable, ...|[monster, make, good, cable...|(137641,[1,5,9,11,12,21,27,...|(137641,[1,5,9,11,12,21,27,...|[0.9954683227075839,8.47663...|     0|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCXoRoEVv-Xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898e9d5b-a850-46ab-f764-73c5a78c361c"
      },
      "source": [
        "processed_review.groupBy('topic#').count().show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|topic#|count|\n",
            "+------+-----+\n",
            "|     1|  231|\n",
            "|     3|  346|\n",
            "|     5| 1260|\n",
            "|     4|  306|\n",
            "|     2| 1637|\n",
            "|     0| 6474|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GllCV-hw7fgL"
      },
      "source": [
        "## 4.3 Top words that define topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxbhwXnQ0dEa"
      },
      "source": [
        "vocab = tf_model.vocabulary\n",
        "\n",
        "def get_words(token_list):\n",
        "     return [vocab[token_id] for token_id in token_list]\n",
        "\n",
        "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhsk4J5p0lOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd0d932-c4ad-46c2-8f1b-d94c9ed17b07"
      },
      "source": [
        "num_top_words = 10\n",
        "\n",
        "topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
        "topics.select('topic', 'topicWords').show(truncate=90)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------------------------------------------------------------------------+\n",
            "|topic|                                                                     topicWords|\n",
            "+-----+-------------------------------------------------------------------------------+\n",
            "|    0|                  [pedal, use, sound, one, get, guitar, like, well, good, work]|\n",
            "|    1|     [volt, tc, bx, voltage, pick, drmkii, filter, shockmount, power, receiver]|\n",
            "|    2|[string, pick, guitar, case, acoustic, daddario, finger, sound, mandolin, play]|\n",
            "|    3|     [keyboard, violin, tuner, snark, case, tune, easy, display, ukulele, vibe]|\n",
            "|    4|               [pin, hole, tuner, drill, string, pick, sound, use, pedal, gate]|\n",
            "|    5|              [amp, guitar, strap, pick, string, great, sound, look, one, well]|\n",
            "+-----+-------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}